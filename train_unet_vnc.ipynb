{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import utils_unet_vnc \n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import os\n",
    "import unet_vnc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed: ensure reproducible training/validation split\n",
    "random.seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# directory with data\n",
    "DATA_DIR = Path.cwd()/'Data_for_model'\n",
    "\n",
    "# Directory to save the weights of the model\n",
    "CHECKPOINTS_DIR = Path.cwd() / \"segmentation_model_weights\"\n",
    "CHECKPOINTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Directory where tensorBoard logs will be saved for each run \n",
    "TENSORBOARD_LOGDIR = Path.cwd() /\"segmentation_runs\" \n",
    "TENSORBOARD_LOGDIR.mkdir(parents=True, exist_ok=True)\n",
    "# print(TENSORBOARD_LOGDIR)\n",
    "\n",
    "# training settings and hyperparameters\n",
    "NO_VALIDATION_SCANS = 2\n",
    "IMAGE_SIZE = [64, 64]\n",
    "BATCH_SIZE = 15\n",
    "N_EPOCHS = 50\n",
    "LEARNING_RATE = 1e-4\n",
    "TOLERANCE = 0.05  # for early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation\n",
    "VNC_scans = [\n",
    "    location\n",
    "    for location in DATA_DIR.glob(\"*\")\n",
    "]\n",
    "random.shuffle (VNC_scans)\n",
    "\n",
    "name_VNC_scan = [os.path.basename(os.path.normpath(str(VNC_scan))) for VNC_scan in VNC_scans]\n",
    "\n",
    "# Split into training/validation dataset after shuffling\n",
    "partition = {\"train\": VNC_scans[:-NO_VALIDATION_SCANS],\n",
    "    \"validation\": VNC_scans[-NO_VALIDATION_SCANS:],}\n",
    "\n",
    "\n",
    "# Load training data: create DataLoader with batching and shuffling \n",
    "training_dataset = utils_unet_vnc.VNCDataset(partition[\"train\"], IMAGE_SIZE)\n",
    "training_dataloader = DataLoader(\n",
    "    training_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    pin_memory=True,)\n",
    "\n",
    "# Load validation data\n",
    "valid_dataset = utils_unet_vnc.VNCDataset(partition[\"validation\"], IMAGE_SIZE)\n",
    "valid_dataloader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    pin_memory=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/537 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m current_valid_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(training_dataloader):\n\u001b[1;32m---> 27\u001b[0m     inputs, targets, VNCscan_names \u001b[38;5;241m=\u001b[39m batch\n\u001b[0;32m     28\u001b[0m     inputs, targets \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), targets\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     30\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad() \u001b[38;5;66;03m# zero gradients\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "# Set model, optimiser and loss function\n",
    "\n",
    "# Loss function: combination of dice score and binary cross entropy\n",
    "loss_function = utils_unet_vnc.DiceBCELoss() \n",
    "\n",
    "# import unet model for vnc segementation\n",
    "unet_model = unet_vnc.UNet().to(device)\n",
    "\n",
    "# Adam optimizer\n",
    "optimizer = torch. optim.Adam(unet_model.parameters(), lr = LEARNING_RATE)\n",
    "\n",
    "# minimum_validation_loss = 10\n",
    "minimum_valid_loss = 10\n",
    "# keep track of training process\n",
    "writer = SummaryWriter(log_dir = TENSORBOARD_LOGDIR)\n",
    "\n",
    "\n",
    "#PS C:\\Users\\eencinas> tensorboard --logdir=\"H:\\CACS_VNC_2907\\segmentation_runs\"\n",
    "\n",
    "\n",
    "# Training loop\n",
    "for epoch in range (N_EPOCHS):\n",
    "    current_train_loss = 0.0\n",
    "    current_valid_loss = 0.0\n",
    "\n",
    "    for batch in tqdm(training_dataloader):\n",
    "        inputs, targets, VNCscan_names = batch\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad() # zero gradients\n",
    "        outputs = unet_model(inputs) # forward pass of the model\n",
    "        loss = loss_function(outputs.float(), targets.float()) # Compute loss\n",
    "        loss.backward() # backpropagate\n",
    "        optimizer.step() # update the parameters of the optimizer using the computed gradients\n",
    "\n",
    "        current_train_loss += loss.item() # update total loss\n",
    "\n",
    "        for VNCscan_name in VNCscan_names:\n",
    "            print(f\"Training...processing scan: {VNCscan_name}\")\n",
    "    \n",
    "    # Evaluate validation loss\n",
    "    with torch.no_grad():\n",
    "        unet_model.eval()\n",
    "        for batch in tqdm(valid_dataloader):\n",
    "            inputs, targets, VNCscan_names = batch\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            outputs = unet_model(inputs)\n",
    "            loss = loss_function(outputs.float(), targets.float())\n",
    "            current_valid_loss += loss.item()\n",
    "\n",
    "            for VNCscan_name in VNCscan_names:\n",
    "                print(f\"Validation...processing scan: {VNCscan_name}\")\n",
    "\n",
    "        unet_model.train()\n",
    "\n",
    "    # print the results\n",
    "    print(f'EPOCH: {epoch+1:0>{len(str(N_EPOCHS))}}/{N_EPOCHS}',end=' ')\n",
    "    # write to tensorboard log\n",
    "    writer.add_scalar(\"Loss/train\", current_train_loss / len(training_dataloader), epoch)\n",
    "    writer.add_scalar(\"Loss/validation\", current_valid_loss / len(valid_dataloader), epoch)\n",
    "    # if validation loss is improving, save model checkpoint # only start saving after 10 epochs\n",
    "    if (current_valid_loss / len(valid_dataloader)) < minimum_valid_loss + TOLERANCE:\n",
    "        minimum_valid_loss = current_valid_loss / len(valid_dataloader)\n",
    "        weights_dict = {k: v.cpu() for k, v in unet_model.state_dict().items()}\n",
    "        if epoch > 9:\n",
    "            torch.save(weights_dict, CHECKPOINTS_DIR / f\"u_net_{epoch}.pth\",)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how images look when corpped to 64\n",
    "# check unet in 3D"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
